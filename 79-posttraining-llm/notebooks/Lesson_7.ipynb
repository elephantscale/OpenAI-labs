{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c720d4-d5c6-4ed2-b086-5e8026c81654",
   "metadata": {},
   "source": [
    "# L7: Online RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40bef7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb945fa-d37e-451f-913f-ef6425a3fb90",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85191910-2548-409e-bd49-6df7880c726e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304e49d-bd1e-469b-a5b4-5edb16ecf344",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from helper import generate_responses, test_model_with_questions, load_model_and_tokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d6026",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b1489-42cd-4d76-ad1a-936810cbbb06",
   "metadata": {},
   "source": [
    "## Prepare for evaluation dataset for Math: GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d2813-5cce-4b47-a160-0c5a32c677ff",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful assistant that solves problems step-by-step. \"\n",
    "    \"Always include the final numeric answer inside \\\\boxed{}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69982ae0-755e-48cf-ba4c-3b83b091fd9a",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "def reward_func(completions, ground_truth, **kwargs):\n",
    "    # Regular expression to capture content inside \\boxed{}\n",
    "    matches = [re.search(r\"\\\\boxed\\{(.*?)\\}\", completion[0]['content']) for completion in completions]\n",
    "    contents = [match.group(1) if match else \"\" for match in matches]\n",
    "    # Reward 1 if the content is the same as the ground truth, 0 otherwise\n",
    "    return [1.0 if c == gt else 0.0 for c, gt in zip(contents, ground_truth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e5b05-a493-4683-91fd-7417885efc0f",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer. \\boxed{72}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Positive Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c273931-6827-4ee1-af1a-83a99bf94bf7",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer \\boxed{71}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Negative Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c8041-39cd-4cd7-a2d7-0ef850959911",
   "metadata": {},
   "source": [
    "## Load the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82e0f1-0e30-4f8b-a603-e84d14cedf23",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "data_num = 5\n",
    "eval_dataset = load_dataset(\"openai/gsm8k\", \"main\")[\"test\"].select(range(data_num))\n",
    "sample_df = eval_dataset.to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8d415-01d1-45e3-a103-6a622f9e9a9c",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "def post_processing(example):\n",
    "    match = re.search(r\"####\\s*(-?\\d+)\", example[\"answer\"])\n",
    "    example[\"ground_truth\"] = match.group(1) if match else None\n",
    "    example[\"prompt\"] = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": example[\"question\"]}\n",
    "    ]\n",
    "    return example\n",
    "eval_dataset = eval_dataset.map(post_processing).remove_columns([\"question\", \"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed78c2-ea93-4ac2-bd6f-5d4391de7c8d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "sample_df = eval_dataset.select(range(5)).to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c13dd-84e3-42ad-87dc-5f98772ec93c",
   "metadata": {},
   "source": [
    "## Load the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86f13c-c969-4c7e-8702-d074ee7a2ce6",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"./models/Qwen/Qwen2.5-0.5B-Instruct\", USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb07589-049d-432e-8001-e6e9175ad806",
   "metadata": {
    "height": 419
   },
   "outputs": [],
   "source": [
    "# Store predictions and ground truths\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    # Run the model to generate an answer\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b31f32-5eaf-476c-8e91-2e28efdc4d3c",
   "metadata": {},
   "source": [
    "## Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c515a8-3728-45fa-88cc-6eb4de839839",
   "metadata": {
    "height": 181
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "train_dataset = dataset[\"train\"]\n",
    " \n",
    "# Apply to dataset\n",
    "train_dataset = train_dataset.map(post_processing)\n",
    "train_dataset = train_dataset.remove_columns([\"question\", \"answer\"])\n",
    "if not USE_GPU:\n",
    "    train_dataset = train_dataset.select(range(10))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57436e8c-9b07-4da1-8fae-4430c6617b36",
   "metadata": {},
   "source": [
    "## GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d678274-5768-4cea-ae20-051488e5d0f3",
   "metadata": {
    "height": 181
   },
   "outputs": [],
   "source": [
    "config = GRPOConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_generations=4, # Can set as high as 64 or 128\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-6,\n",
    "    logging_steps=2,\n",
    "    no_cuda= not USE_GPU     # keeps the whole run on CPU, incl. MPS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbb05d-fde6-4de4-8263-ea2057060045",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Note:</b> We're performing GROP on a small model <code>HuggingFaceTB/SmolLM2-135M-Instruct</code> and a smaller training dataset to to ensure the full training process can run on limited computational resources. If you're running the notebooks on your own machine and have access to a GPU, feel free to switch to a larger model‚Äîsuch as <code>Qwen/Qwen2.5-0.5B-Instruct</code>‚Äîto perform full GRPO and reproduce the results shown above.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d5896-6fd6-43d2-85f1-dacbd594f4cf",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "## If this block hangs or the kernel restarts during training, please skip loading the previous 0.5B model for evaluation\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\"./models/HuggingFaceTB/SmolLM2-135M-Instruct\", USE_GPU)\n",
    "\n",
    "grpo_trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    args=config,\n",
    "    reward_funcs=reward_func,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "grpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a33533-3f0c-4d1c-a5ef-f0ba1ff61a5f",
   "metadata": {},
   "source": [
    "## Results of the fully trained Qwen model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08666571-bda3-45f3-99cc-8593c116a115",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**Note:** Due to limited computational resources, we used a small model and dataset for GRPO training. However, the following results are from a fully trained larger model‚Äî**Qwen2.5-0.5B**‚Äîto demonstrate the complete outcome of the GRPO process. To view results from the smaller model and dataset, set **fully_trained_qwen** to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521a00a-88d8-4ad9-b134-12ea94e76984",
   "metadata": {
    "height": 521
   },
   "outputs": [],
   "source": [
    "fully_trained_qwen = True\n",
    "if fully_trained_qwen:\n",
    "    model, tokenizer = load_model_and_tokenizer(\"./models/banghua/Qwen2.5-0.5B-GRPO\", \n",
    "                                            USE_GPU)\n",
    "else:\n",
    "    model = grpo_trainer.model\n",
    "\n",
    "# Store predictions and ground truths\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    # Run the model to generate an answer\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edfd3c-0ea7-43cd-90d6-6c0d8e2216e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa3e26-e46c-409f-be94-7475e6c91dbe",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5db8c-fe2c-46e5-b9ab-2ce6ec309fb1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8623c-8125-48bf-b482-8147b0d75831",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a42fb-9ea9-4e33-90d0-c0bf1b676439",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1cfb-6cc0-4a76-be8a-a1a10f60b7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
