{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce539cc-440f-418c-8991-fbaf9196be93",
   "metadata": {},
   "source": [
    "# Lesson 4: Deploy an AWS Lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4b464-256d-446d-9910-5523a810659b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43fa83e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import boto3, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90d0cccb-ee62-4a8f-8672-0d6213cca069",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "from helpers.Lambda_Helper import Lambda_Helper\n",
    "from helpers.S3_Helper import S3_Helper\n",
    "from helpers.Display_Helper import Display_Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd760402-f4dd-435f-9b90-aac520ae960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "os.environ['LAMBDALAYERVERSIONARN'] = 'arn:aws:lambda:us-west-2:092413168457:layer:dlai-bedrock-jinja-layer:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0115c012",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "lambda_helper = Lambda_Helper()\n",
    "# deploy_function\n",
    "# add_lambda_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9785005",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "s3_helper = S3_Helper()\n",
    "# upload_file\n",
    "# download_object \n",
    "# list_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f93593c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "display_helper = Display_Helper()\n",
    "# text_file\n",
    "# json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f33a0909-99c0-4fd8-9d0c-753d12dd4045",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "bucket_name_text = os.getenv('BucketName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce1dc532",
   "metadata": {
    "height": 538
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prompt_template.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile prompt_template.txt\n",
    "I need to summarize a conversation. The transcript of the conversation is between the <data> XML like tags.\n",
    "\n",
    "<data>\n",
    "{{transcript}}\n",
    "</data>\n",
    "\n",
    "The summary must contain a one word sentiment analysis, and a list of issues, problems or causes of friction\n",
    "during the conversation. The output must be provided in JSON format shown in the following example. \n",
    "\n",
    "Example output:\n",
    "{\n",
    "    \"version\": 0.1,\n",
    "    \"sentiment\": <sentiment>,\n",
    "    \"issues\": [\n",
    "        {\n",
    "            \"topic\": <topic>,\n",
    "            \"summary\": <issue_summary>,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "An `issue_summary` must only be one of:\n",
    "{%- for topic in topics %}\n",
    " - `{{topic}}`\n",
    "{% endfor %}\n",
    "\n",
    "Write the JSON output and nothing more.\n",
    "\n",
    "Here is the JSON output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "680d354d",
   "metadata": {
    "height": 45
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_template.txt:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width: 600px; word-wrap: break-word;'><pre>I need to summarize a conversation. The transcript of the conversation is between the &lt;data&gt; XML like tags.<br><br>&lt;data&gt;<br>{{transcript}}<br>&lt;/data&gt;<br><br>The summary must contain a one word sentiment analysis, and a list of issues, problems or causes of friction<br>during the conversation. The output must be provided in JSON format shown in the following example. <br><br>Example output:<br>{<br>    &quot;version&quot;: 0.1,<br>    &quot;sentiment&quot;: &lt;sentiment&gt;,<br>    &quot;issues&quot;: [<br>        {<br>            &quot;topic&quot;: &lt;topic&gt;,<br>            &quot;summary&quot;: &lt;issue_summary&gt;,<br>        }<br>    ]<br>}<br><br>An `issue_summary` must only be one of:<br>{%- for topic in topics %}<br> - `{{topic}}`<br>{% endfor %}<br><br>Write the JSON output and nothing more.<br><br>Here is the JSON output:<br></pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_helper.text_file('prompt_template.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acb14e-ca71-49fa-923b-ca180c8e2eaa",
   "metadata": {},
   "source": [
    "### Create the Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df062c80",
   "metadata": {
    "height": 2221
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_function.py\n",
    "\n",
    "\n",
    "#############################################################\n",
    "#\n",
    "# This Lambda function is written to a file by the notebook \n",
    "# It does not run in the notebook!\n",
    "#\n",
    "#############################################################\n",
    "\n",
    "import boto3\n",
    "import json \n",
    "from jinja2 import Template\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', 'us-west-2')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    # One of a few different checks to ensure we don't end up in a recursive loop.\n",
    "    if \"-transcript.json\" not in key: \n",
    "        print(\"This demo only works with *-transcript.json.\")\n",
    "        return\n",
    "    \n",
    "    try: \n",
    "        file_content = \"\"\n",
    "        \n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        \n",
    "        file_content = response['Body'].read().decode('utf-8')\n",
    "        \n",
    "        transcript = extract_transcript_from_textract(file_content)\n",
    "\n",
    "        print(f\"Successfully read file {key} from bucket {bucket}.\")\n",
    "\n",
    "        print(f\"Transcript: {transcript}\")\n",
    "        \n",
    "        summary = bedrock_summarisation(transcript)\n",
    "        \n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key='results.txt',\n",
    "            Body=summary,\n",
    "            ContentType='text/plain'\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error occurred: {e}\")\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(f\"Successfully summarized {key} from bucket {bucket}. Summary: {summary}\")\n",
    "    }\n",
    "        \n",
    "        \n",
    "        \n",
    "def extract_transcript_from_textract(file_content):\n",
    "\n",
    "    transcript_json = json.loads(file_content)\n",
    "\n",
    "    output_text = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    items = transcript_json['results']['items']\n",
    "\n",
    "    # Iterate through the content word by word:\n",
    "    for item in items:\n",
    "        speaker_label = item.get('speaker_label', None)\n",
    "        content = item['alternatives'][0]['content']\n",
    "        \n",
    "        # Start the line with the speaker label:\n",
    "        if speaker_label is not None and speaker_label != current_speaker:\n",
    "            current_speaker = speaker_label\n",
    "            output_text += f\"\\n{current_speaker}: \"\n",
    "        \n",
    "        # Add the speech content:\n",
    "        if item['type'] == 'punctuation':\n",
    "            output_text = output_text.rstrip()  # Remove the last space\n",
    "        \n",
    "        output_text += f\"{content} \"\n",
    "        \n",
    "    return output_text\n",
    "        \n",
    "\n",
    "def bedrock_summarisation(transcript):\n",
    "    \n",
    "    with open('prompt_template.txt', \"r\") as file:\n",
    "        template_string = file.read()\n",
    "\n",
    "    data = {\n",
    "        'transcript': transcript,\n",
    "        'topics': ['charges', 'location', 'availability']\n",
    "    }\n",
    "    \n",
    "    template = Template(template_string)\n",
    "    prompt = template.render(data)\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    kwargs = {\n",
    "        \"modelId\": \"amazon.titan-text-express-v1\",\n",
    "        \"contentType\": \"application/json\",\n",
    "        \"accept\": \"*/*\",\n",
    "        \"body\": json.dumps(\n",
    "            {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 2048,\n",
    "                    \"stopSequences\": [],\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(**kwargs)\n",
    "\n",
    "    summary = json.loads(response.get('body').read()).get('results')[0].get('outputText')    \n",
    "    return summary\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75deb539",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping function...\n",
      "Looking for existing function...\n",
      "Function LambdaFunctionSummarize does not exist. Creating...\n"
     ]
    },
    {
     "ename": "InvalidParameterValueException",
     "evalue": "An error occurred (InvalidParameterValueException) when calling the CreateFunction operation: The role defined for the function cannot be assumed by Lambda.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundException\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/L4/helpers/Lambda_Helper.py:46\u001b[0m, in \u001b[0;36mLambda_Helper.deploy_function\u001b[0;34m(self, code_file_names, function_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Try to get the details of the Lambda function\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFunctionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# If the function exists, update its code\u001b[39;00m\n",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/53/lib/python3.11/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/53/lib/python3.11/site-packages/botocore/client.py:983\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    982\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mResourceNotFoundException\u001b[0m: An error occurred (ResourceNotFoundException) when calling the GetFunction operation: Function not found: arn:aws:lambda:us-west-2:092413168457:function:LambdaFunctionSummarize",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidParameterValueException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlambda_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlambda_function.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_template.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLambdaFunctionSummarize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/L4/helpers/Lambda_Helper.py:61\u001b[0m, in \u001b[0;36mLambda_Helper.deploy_function\u001b[0;34m(self, code_file_names, function_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_client\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mResourceNotFoundException:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# If the function does not exist, create a new one\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist. Creating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFunctionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRuntime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython3.11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mHandler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda_function.lambda_handler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLAMBDALAYERVERSIONARN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZipFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEnvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVariables\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambda_environ_variables\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctionArn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_arn \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctionArn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/53/lib/python3.11/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OpenAI-labs/53-Serverless-LLM-Bedrock/53/lib/python3.11/site-packages/botocore/client.py:983\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    979\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mInvalidParameterValueException\u001b[0m: An error occurred (InvalidParameterValueException) when calling the CreateFunction operation: The role defined for the function cannot be assumed by Lambda."
     ]
    }
   ],
   "source": [
    "lambda_helper.deploy_function(\n",
    "    [\"lambda_function.py\", \"prompt_template.txt\"],\n",
    "    function_name=\"LambdaFunctionSummarize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676e124",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "lambda_helper.filter_rules_suffix = \"json\"\n",
    "lambda_helper.add_lambda_trigger(bucket_name_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cf2b4",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "# display_helper.json_file('demo-transcript.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9cd84",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "s3_helper.upload_file(bucket_name_text, 'demo-transcript.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8c684-9250-4682-b819-f01d2325bd46",
   "metadata": {},
   "source": [
    "#### Restart kernel if needed.\n",
    "- If you run the code fairly quickly from start to finish, it's possible that the following code cell `s3_helper.list_objects(bucket_name_text)` will give a \"Not Found\" error.  \n",
    "- If waiting a few seconds (10 seconds) and re-running this cell does not resolve the error, then you can restart the kernel of the jupyter notebook.\n",
    "- Go to menu->Kernel->Restart Kernel.\n",
    "- Then run the code cells from the start of the notebook, waiting 2 seconds or so for each code cell to finish executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585029c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "s3_helper.list_objects(bucket_name_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee10b9-9c52-4a2a-8207-fc3c6ad21a8d",
   "metadata": {},
   "source": [
    "#### Re-run \"download\" code cell as needed\n",
    "- It may take a few seconds for the results to be generated.\n",
    "- If you see a `Not Found` error, please wait a few seconds and then try running the `s3_helper.download_object` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d70063",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "s3_helper.download_object(bucket_name_text, \"results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4e625",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display_helper.text_file('results.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
