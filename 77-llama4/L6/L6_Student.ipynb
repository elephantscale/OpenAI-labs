{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c190e92f-9245-4333-a532-1fae97f41c27",
   "metadata": {},
   "source": [
    "# Prompt Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350abad-e099-4e7b-8d4d-e37fc9285fc6",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06c78c-3a80-4ee3-8198-4a633045e699",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fe38d6-537f-416a-a3ad-08fbdd541488",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2876631c-db76-43d8-8f20-bc964d070cf1",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_llama_api_key, get_llama_base_url, get_together_api_key\n",
    "\n",
    "llama_api_key = get_llama_api_key()\n",
    "llama_base_url = get_llama_base_url()\n",
    "together_api_key = get_together_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a6a1a8-53d9-4ba1-9367-e45d62fd711c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!pip install llama-prompt-ops==0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e4fb0-a0a9-43cb-b636-e8c9654f7075",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db02ff-234d-4f19-b656-641fd125ff94",
   "metadata": {},
   "source": [
    "## Creating a sample project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c55a8f-5082-4166-8b9c-6f65c4c6754b",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "## Check if the folder exists: In the line [ -d \"my-project\" ] returns true if the directory is present; the || (‚Äúor‚Äù) means llama-prompt-ops create my-project executes only when that first test is false\n",
    "![ -d \"my-project\" ] || llama-prompt-ops create my-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b85284c-10b9-4593-bd0d-82aeb9fc06c6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  config.yaml\tdata  prompts  results\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./my-project/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c78821-19c1-463d-9305-5fc97bee763c",
   "metadata": {},
   "source": [
    "## System prompt and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53d0950-b3c7-4713-99bc-47a8d1a1fc04",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant. Extract and return a json with the following keys and values:\r\n",
      "- \"urgency\" as one of `high`, `medium`, `low`\r\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\r\n",
      "- \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value indicates whether the category is one of the best matching support category tags from: `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, `facility_management_issues`\r\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\r\n"
     ]
    }
   ],
   "source": [
    "!cat my-project/prompts/prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08521291-31dc-4f85-8aa1-86b8b965a82c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"fields\": {\r\n",
      "      \"input\": \"Subject: Urgent Assistance Required for Specialized Cleaning Services\\n\\nDear ProCare Facility Solutions Support Team,\\n\\nI hope this message finds you well. My name is [Sender], and my family and I have been availing your services for our home for the past year. We have always appreciated the high standards and professionalism your team brings to maintaining our living environment.\\n\\nHowever, we are currently facing an urgent issue that requires immediate attention. We recently hosted a large gathering at our home, and despite our best efforts, there are several areas that now require specialized cleaning. Specifically, we need deep cleaning for our carpets and upholstery, as well as thorough window washing. The situation is quite pressing as we have more guests arriving soon, and we want to ensure our home is in pristine condition to welcome them.\\n\\nWe have tried some basic cleaning ourselves, but the results have not been satisfactory. Given the high standards we have come to expect from ProCare, we are confident that your team can handle this situation efficiently and effectively.\\n\\nCould you please arrange for a specialized cleaning team to visit our home at the earliest convenience? We would greatly appreciate it if this could be prioritized due to the urgency of the situation.\\n\\nThank you for your prompt attention to this matter. We look forward to your swift response and assistance.\\n\\nBest regards,\\n[Sender]\"\r\n",
      "    },\r\n",
      "    \"answer\": \"{\\\"categories\\\": {\\\"routine_maintenance_requests\\\": false, \\\"customer_feedback_and_complaints\\\": false, \\\"training_and_support_requests\\\": false, \\\"quality_and_safety_concerns\\\": false, \\\"sustainability_and_environmental_practices\\\": false, \\\"cleaning_services_scheduling\\\": false, \\\"specialized_cleaning_services\\\": true, \\\"emergency_repair_services\\\": false, \\\"facility_management_issues\\\": false, \\\"general_inquiries\\\": false}, \\\"sentiment\\\": \\\"neutral\\\", \\\"urgency\\\": \\\"high\\\"}\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"fields\": {\r\n",
      "      \"input\": \"Subject: Inquiry About Specialized Cleaning Services\\n\\nHi ProCare Support Team,\\n\\nI hope this message finds you well. My name is Alex, and I've been a client of ProCare Facility Solutions for a few months now. I must say, your services have been quite satisfactory so far, especially the routine maintenance and cleaning schedules.\\n\\nI am reaching out to inquire about your specialized cleaning services. Specifically, I am interested in deep cleaning and carpet maintenance for my residential property. While the regular cleaning has been great, I feel that a more thorough cleaning would really help maintain the pristine condition of my home.\\n\\nI haven't taken any steps yet to address this, as I wanted to get more information from your team first. Could you please provide me with details on how these specialized services work, the scheduling options available, and any additional costs involved?\\n\\nLooking forward to your response.\\n\\nBest regards,\\nAlex\"\r\n",
      "    },\r\n",
      "    \"answer\": \"{\\\"categories\\\": {\\\"routine_maintenance_requests\\\": false, \\\"customer_feedback_and_complaints\\\": false, \\\"training_and_support_requests\\\": false, \\\"quality_and_safety_concerns\\\": false, \\\"sustainability_and_environmental_practices\\\": false, \\\"cleaning_services_scheduling\\\": false, \\\"specialized_cleaning_services\\\": true, \\\"emergency_repair_services\\\": false, \\\"facility_management_issues\\\": false, \\\"general_inquiries\\\": true}, \\\"sentiment\\\": \\\"neutral\\\", \\\"urgency\\\": \\\"low\\\"}\"\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"fields\": {\r\n"
     ]
    }
   ],
   "source": [
    "!head -15 my-project/data/dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378a2ff9-ea3e-481f-b215-ab342340d2ee",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_prompt:\r\n",
      "  file: prompts/prompt.txt\r\n",
      "  inputs:\r\n",
      "  - question\r\n",
      "  outputs:\r\n",
      "  - answer\r\n",
      "dataset:\r\n",
      "  path: data/dataset.json\r\n",
      "  input_field:\r\n",
      "  - fields\r\n",
      "  - input\r\n",
      "  golden_output_field: answer\r\n",
      "model:\r\n",
      "  task_model: together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\r\n",
      "  proposer_model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\r\n",
      "  api_base: https://api.together.xyz/v1\r\n",
      "metric:\r\n",
      "  class: llama_prompt_ops.core.metrics.FacilityMetric\r\n",
      "  strict_json: false\r\n",
      "  output_field: answer\r\n",
      "optimization:\r\n",
      "  strategy: llama\r\n"
     ]
    }
   ],
   "source": [
    "!cat my-project/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98397945-4c85-48df-b464-b954464d2486",
   "metadata": {
    "height": 436
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my-project/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile my-project/config.yaml\n",
    "system_prompt:\n",
    "  file: prompts/prompt.txt\n",
    "  inputs:\n",
    "  - question\n",
    "  outputs:\n",
    "  - answer\n",
    "dataset:\n",
    "  path: data/dataset.json\n",
    "  input_field:\n",
    "  - fields\n",
    "  - input\n",
    "  golden_output_field: answer\n",
    "model:\n",
    "  task_model: together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\n",
    "  proposer_model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
    "  api_base: https://api.together.xyz/v1\n",
    "metric:\n",
    "  class: llama_prompt_ops.core.metrics.FacilityMetric\n",
    "  strict_json: false\n",
    "  output_field: answer\n",
    "optimization:\n",
    "  strategy: llama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d3a27-d4e8-4f44-be33-c2a1f77b1ce9",
   "metadata": {},
   "source": [
    "## Running prompt optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcde8a-9d4f-4b11-be4a-91c3933cf014",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p>Running prompt optimization can take a long time. To speed up running the notebooks, we will load saved results. You can change <code>run_optimization</code> to <code>True</code> to run the optimization.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f49a6d5-51fe-4a21-8b3d-f4f5f1b8870f",
   "metadata": {
    "height": 96,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_optimization = False     # or chnage to True to run\n",
    "\n",
    "if run_optimization:\n",
    "    !cd my-project && llama-prompt-ops migrate --api-key-env TOGETHERAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cb2f6-0966-4ce9-b2b0-60b96503f1a8",
   "metadata": {},
   "source": [
    "## Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2b2a97-24c1-401e-a362-7cfbbb83697d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "json_files = glob.glob(\"my-project/results/*.json\")\n",
    "\n",
    "import json\n",
    "with open(json_files[0], \"r\") as f:\n",
    "    data = json.load(f)\n",
    "optimized_prompt = data['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe1bf0d-4b34-4b18-adc6-0bf5ab01967b",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "with open(\"my-project/prompts/prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    original_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56937fce-0f3c-4812-a7d8-9f8fd4aa9244",
   "metadata": {
    "height": 181
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width: 100%; border-collapse: collapse;\"><tr><th>Original Prompt</th><th>Optimized Prompt</th></tr><tr><td style=\"width:50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">You are a helpful assistant. Extract and return a json with the following keys and values:\n",
       "- \"urgency\" as one of `high`, `medium`, `low`\n",
       "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
       "- \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value indicates whether the category is one of the best matching support category tags from: `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, `facility_management_issues`\n",
       "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
       "</pre></td><td style=\"width: 50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">You are a customer support specialist for ProCare Facility Solutions, tasked with analyzing incoming customer inquiries and requests. Extract and return a json with the following keys and values: - \"urgency\" as one of `high`, `medium`, `low` - \"sentiment\" as one of `negative`, `neutral`, `positive` - \"categories\" Create a dictionary with categories as keys and boolean values (True/False), where the value indicates whether the category is one of the best matching support category tags from: `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, `facility_management_issues`. Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above.</pre></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def compare_strings_side_by_side(text1, text2):\n",
    "    html = '<table style=\"width: 100%; border-collapse: collapse;\"><tr><th>Original Prompt</th><th>Optimized Prompt</th></tr>'\n",
    "    html += f'<tr><td style=\"width:50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">{text1}</pre></td><td style=\"width: 50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">{text2}</pre></td></tr></table>'\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "compare_strings_side_by_side(original_prompt, optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be468a56-effe-4ed4-960e-1020315c914f",
   "metadata": {},
   "source": [
    "## Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5297b14-aa9c-4ecc-b94d-1f934743afc3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: Request for Training and Support on Facility Management Best Practices\\n\\nDear ProCare Support Team,\\n\\nI hope this message finds you well. My name is Dr. Alex Turner, and I am a wildlife ecologist who has been utilizing your facility management services for our research center. We have been quite satisfied with the overall maintenance and cleaning services provided by ProCare Facility Solutions.\\n\\nI am reaching out to request some additional training and support for our in-house maintenance team. As our research activities expand, we find ourselves needing to better understand the best practices in facility management, particularly in areas related to energy efficiency and environmental impact reduction. This knowledge is crucial for us to maintain our facility in a way that aligns with our ecological research goals.\\n\\nSo far, we have tried to implement some basic practices based on general guidelines, but we believe that a more structured training program from your experts would be highly beneficial. We are looking for comprehensive training sessions that can be scheduled at a convenient time for our team.\\n\\nCould you please provide us with information on the available training programs and how we can arrange for these sessions? Additionally, any resources or documentation that could help us in the interim would be greatly appreciated.\\n\\nThank you for your attention to this matter. We look forward to your guidance and support.\\n\\nBest regards,\\n\\nDr. Alex Turner  \\nWildlife Ecologist  \\n[Sender]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['few_shots'][0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9476d0-35f5-488d-897f-0e3bbcde2524",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"categories\": {\"routine_maintenance_requests\": false, \"customer_feedback_and_complaints\": false, \"training_and_support_requests\": true, \"quality_and_safety_concerns\": false, \"sustainability_and_environmental_practices\": true, \"cleaning_services_scheduling\": false, \"specialized_cleaning_services\": false, \"emergency_repair_services\": false, \"facility_management_issues\": true, \"general_inquiries\": false}, \"sentiment\": \"neutral\", \"urgency\": \"low\"}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['few_shots'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3359dc9e-9bf2-4272-88ae-41a8a7a46702",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['few_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab19cc5b-2fdc-4b05-a6b2-71f6af2ca0cf",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "few_shots = \"\\n\\nFew shot examples\\n\\n\"\n",
    "for i, shot in enumerate(data['few_shots']):\n",
    "  few_shots += f\"\"\"Example {i+1}\\n=================\\nQuestion:\\n\n",
    "  {shot['question']}\\n\\nAnswer:\\n{shot['answer']}\\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c36ff-3060-4857-8f6e-e98e9b007619",
   "metadata": {},
   "source": [
    "## Compare optimized and original prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f584214-3e31-4b9e-b666-d7a8d6908515",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"my-project/data/dataset.json\", 'r') as f:\n",
    "  ds = json.load(f)\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bbdaa7b-40ae-43ea-94fb-7f8ea99f3f59",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = ds[int(len(ds)*0.7):]\n",
    "len(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb396e81-9458-4330-823e-7598e5f7c6f5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30979087-60fd-4871-a9dc-11774227a7a3",
   "metadata": {
    "height": 353
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1ec404f86047daba8e97967b7bb446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from together import Together\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "result_original = []\n",
    "client = Together()\n",
    "\n",
    "for entry in tqdm(ds_test):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": original_prompt},\n",
    "        {\"role\": \"user\", \"content\": entry[\"fields\"][\"input\"]},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "      messages=messages,\n",
    "      temperature=0\n",
    "    )\n",
    "\n",
    "    prediction = response.choices[0].message.content\n",
    "    result_original.append(evaluate(entry[\"answer\"], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb88844f-1a18-4be1-9da5-2a9fdb2b9625",
   "metadata": {
    "height": 300
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a661f3be94426abfd9e61d0ee6de94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_optimized = []\n",
    "\n",
    "for entry in tqdm(ds_test):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": optimized_prompt + few_shots},\n",
    "        {\"role\": \"user\", \"content\": entry[\"fields\"][\"input\"]},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "      messages=messages,\n",
    "      temperature=0\n",
    "    )\n",
    "\n",
    "    prediction = response.choices[0].message.content\n",
    "    result_optimized.append(evaluate(entry[\"answer\"], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd5b9d6-3d17-494e-89ee-d25c144622fa",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_valid_json': True,\n",
       " 'correct_categories': 0.8,\n",
       " 'correct_sentiment': True,\n",
       " 'correct_urgency': True,\n",
       " 'total': 0.9333333333333332}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_optimized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa27268-9e3c-477c-b7fc-9284c7df11ef",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_valid_json': True,\n",
       " 'correct_categories': 0.9,\n",
       " 'correct_sentiment': False,\n",
       " 'correct_urgency': True,\n",
       " 'total': 0.6333333333333333}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_optimized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10141053-db33-435e-812c-0e5549c638e8",
   "metadata": {
    "height": 79
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_valid_json': 1.0,\n",
       " 'correct_categories': 0.9349999999999998,\n",
       " 'correct_sentiment': 0.5,\n",
       " 'correct_urgency': 0.8666666666666667,\n",
       " 'total': 0.7672222222222221}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_keys = [k for k, v in result_original[0].items() if isinstance(v,\n",
    "                                                (int, float, bool))]\n",
    "{k: sum([e[k] for e in result_original])/len(result_original) for k in float_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed502c37-21f9-4421-9705-cdea6c9759a8",
   "metadata": {
    "height": 45
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_valid_json': 1.0,\n",
       " 'correct_categories': 0.948333333333333,\n",
       " 'correct_sentiment': 0.7,\n",
       " 'correct_urgency': 0.9333333333333333,\n",
       " 'total': 0.8605555555555552}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: sum([e[k] for e in result_optimized])/len(result_optimized) for k in float_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe99719-9560-4ace-9717-56ee31eebdc2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae96c70-965d-4b8b-a63c-d8107f53284a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62531e29-5e87-43e8-9173-2329dd8a046d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22af04-f412-4b7f-a248-11e9204c9d91",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59b1b2-c569-452d-98c1-ccb4c2f4827d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057437d5-7e48-4cf6-a931-424f679e262e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
