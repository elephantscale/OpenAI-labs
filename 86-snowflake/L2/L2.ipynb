{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Lesson 2: Construct a Multi-Agent Workflow\n",
    "\n",
    "In this lesson, you'll build a data agent that can perform web research, answer questions, and generate charts.\n",
    "\n",
    "Let's load the environment variables that define the OpenAI API and Tavily API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2172e54",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbe8c9",
   "metadata": {},
   "source": [
    "**Note**: These variables are already defined in this environment. If you'd like to run the notebook locally, you can define them in a `.env` file. For an env template, you can check the file `env.template` in this lesson's folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551424b-6334-4c9b-8dc3-9c61a2347b62",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b>To access <code>requirements.txt</code>, <code>env.template</code>, <code>prompts.py</code>, and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6570f-c8ad-4176-8e25-94bc53a4a780",
   "metadata": {},
   "source": [
    "## 2.1 Initialize the agent's state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf984dd",
   "metadata": {},
   "source": [
    "State provides the agent with a shared, evolving memory across nodes so that the agents have the context and instructions needed to act coherently and achieve the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65289f3",
   "metadata": {
    "height": 249
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, List, Dict, Any, Type\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Custom State class with specific keys\n",
    "class State(MessagesState):\n",
    "    user_query: Optional[str] # The user's original query\n",
    "    enabled_agents: Optional[List[str]] # Makes our multi-agent system modular on which agents to include\n",
    "    plan: Optional[List[Dict[int, Dict[str, Any]]]] # Listing the steps in the plan needed to achieve the goal.\n",
    "    current_step: int # Marking the current step in the plan.\n",
    "    agent_query: Optional[str] # Inbox note: `agent_query` tells the next agent exactly what to do at the current step.\n",
    "    last_reason: Optional[str] # Explains the executor’s decision to help maintain continuity and provide traceability.\n",
    "    replan_flag: Optional[bool] # Set by the executor to indicate that the planner should revise the plan.\n",
    "    replan_attempts: Optional[Dict[int, Dict[int, int]]] # Replan attempts tracked per step number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2b7fa-56e0-46dc-97c4-9e0a79ff0508",
   "metadata": {},
   "source": [
    "**Note**: `State` inherits from `MessagesState`, which is defined with a single `messages` key that keeps track of the list of messages shared among agents. So in addition to the fields you just defined for `State`, it also has a `messages` field from `MessagesState`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbb6b7-62fe-4ac0-b557-36cfeb102897",
   "metadata": {},
   "source": [
    "## 2.2 Create planner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cd82b",
   "metadata": {},
   "source": [
    "The planner takes in the user's query and generates a plan. The plan consists of a sequence of numbered steps; each step includes the action and the sub-agent that is assigned to that action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e263cc1-2e9a-4d6d-ae4a-ca12935c2e7a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from prompts import plan_prompt\n",
    "from langgraph.types import Command\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164f8e6-5c20-4451-b865-b5497e6cb04d",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model=\"o3\",\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff2f4f",
   "metadata": {
    "height": 623
   },
   "outputs": [],
   "source": [
    "def planner_node(state: State) -> Command[Literal['executor']]:\n",
    "    \"\"\"\n",
    "    Runs the planning LLM and stores the resulting plan in state.\n",
    "    \"\"\"\n",
    "    # 1. Invoke LLM with the planner prompt\n",
    "    llm_reply = reasoning_llm.invoke([plan_prompt(state)])\n",
    "\n",
    "    # 2. Validate JSON\n",
    "    try:\n",
    "        content_str = llm_reply.content if isinstance(\n",
    "            llm_reply.content, str) else str(llm_reply.content)\n",
    "        parsed_plan = json.loads(content_str)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\n",
    "            f\"Planner returned invalid JSON:\\n{llm_reply.content}\")\n",
    "\n",
    "    # 3. Store as current plan only\n",
    "    replan = state.get(\"replan_flag\", False)\n",
    "    updated_plan: Dict[str, Any] = parsed_plan\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"plan\": updated_plan,\n",
    "            \"messages\": [HumanMessage(\n",
    "                content=llm_reply.content,\n",
    "                name=\"replan\" if replan else \"initial_plan\")],\n",
    "            \"user_query\": state.get(\"user_query\", state[\"messages\"][0].content),\"current_step\": 1 if not replan else state[\"current_step\"],\n",
    "            # Preserve replan flag so executor runs planned agent\n",
    "            # once before reconsidering\n",
    "            \"replan_flag\": state.get(\"replan_flag\", False),\n",
    "            \"last_reason\": \"\",\n",
    "            \"enabled_agents\": state.get(\"enabled_agents\"),\n",
    "        },\n",
    "        goto=\"executor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140771f4",
   "metadata": {},
   "source": [
    "## 2.3 Create executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76583902",
   "metadata": {},
   "source": [
    "The executor executes the plan by identifying the sub-agent that should go next and generating the instructions (or agent query) for the chosen agent. Based on the results of the retrieval step (web search results in this case), the executor might decide that the plan needs to be changed. In this case, it goes back to the planner and asks it to generate an updated plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede02bc-758d-4d39-9941-6d47520b98a7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from prompts import executor_prompt\n",
    "from langgraph.graph import END\n",
    "\n",
    "MAX_REPLANS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422bcfe",
   "metadata": {
    "height": 1099
   },
   "outputs": [],
   "source": [
    "def executor_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"web_researcher\", \"chart_generator\", \"synthesizer\", \"planner\"]]:\n",
    "\n",
    "    plan: Dict[str, Any] = state.get(\"plan\", {})\n",
    "    step: int = state.get(\"current_step\", 1)\n",
    "\n",
    "    # 0) If we *just* replanned, \n",
    "    # run the planned agent once before reconsidering.\n",
    "    if state.get(\"replan_flag\"):\n",
    "        planned_agent = plan.get(str(step), {}).get(\"agent\")\n",
    "        return Command(\n",
    "            update={\n",
    "                \"replan_flag\": False,\n",
    "                \"current_step\": step + 1,  # advance because we executed the planned agent\n",
    "            },\n",
    "            goto=planned_agent,\n",
    "        )\n",
    "\n",
    "    # 1) Build prompt & call LLM\n",
    "    llm_reply = reasoning_llm.invoke([executor_prompt(state)])\n",
    "    try:\n",
    "        content_str = llm_reply.content if isinstance(llm_reply.content, str) else str(llm_reply.content)\n",
    "        parsed = json.loads(content_str)\n",
    "        replan: bool = parsed[\"replan\"]\n",
    "        goto: str   = parsed[\"goto\"]\n",
    "        reason: str = parsed[\"reason\"]\n",
    "        query: str  = parsed[\"query\"]\n",
    "    except Exception as exc:\n",
    "        raise ValueError(f\"Invalid executor JSON:\\n{llm_reply.content}\") from exc\n",
    "\n",
    "    # Upodate the state\n",
    "    updates: Dict[str, Any] = {\n",
    "        \"messages\": [HumanMessage(content=llm_reply.content, name=\"executor\")],\n",
    "        \"last_reason\": reason,\n",
    "        \"agent_query\": query,\n",
    "    }\n",
    "\n",
    "    # Replan accounting\n",
    "    replans: Dict[int, int] = state.get(\"replan_attempts\", {}) or {}\n",
    "    step_replans = replans.get(step, 0)\n",
    "\n",
    "    # 2) Replan decision\n",
    "    if replan:\n",
    "        if step_replans < MAX_REPLANS:\n",
    "            replans[step] = step_replans + 1\n",
    "            updates.update({\n",
    "                \"replan_attempts\": replans,\n",
    "                \"replan_flag\": True,     # ensure next turn executes the planned agent once\n",
    "                \"current_step\": step,    # stay on same step for the new plan\n",
    "            })\n",
    "            return Command(update=updates, goto=\"planner\")\n",
    "        else:\n",
    "            # Cap hit: skip this step; let next step (or synthesizer) handle termination\n",
    "            next_agent = plan.get(str(step + 1), {}).get(\"agent\", \"synthesizer\")\n",
    "            updates[\"current_step\"] = step + 1\n",
    "            return Command(update=updates, goto=next_agent)\n",
    "\n",
    "    # 3) Happy path: run chosen agent; advance only if following the plan\n",
    "    planned_agent = plan.get(str(step), {}).get(\"agent\")\n",
    "    updates[\"current_step\"] = step + 1 if goto == planned_agent else step\n",
    "    updates[\"replan_flag\"] = False\n",
    "    return Command(update=updates, goto=goto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b75e40",
   "metadata": {},
   "source": [
    "## 2.4 Create Web research agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ae2d5",
   "metadata": {},
   "source": [
    "The web research sub-agent is a [ReAct agent](https://arxiv.org/abs/2210.03629) that uses [Tavily Search tool](https://python.langchain.com/docs/integrations/tools/tavily_search/) to search the web and answer the sub-query assigned to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d926a",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Literal\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "\n",
    "tavily_tool.invoke(\"What is JP Morgan's stock price?\")['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526c0e4",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "from helper import agent_system_prompt\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Research agent and node\n",
    "web_search_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[tavily_tool],\n",
    "    prompt=agent_system_prompt(f\"\"\"\n",
    "        You are the Researcher. You can ONLY perform research \n",
    "        by using the provided search tool (tavily_tool). \n",
    "        When you have found the necessary information, end your output.  \n",
    "        Do NOT attempt to take further actions.\n",
    "    \"\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9694060",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "agent_response = web_search_agent.invoke(\n",
    "    {\"messages\":\"what is jp morgan's current market cap?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552977a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "agent_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a44ebf-4a1d-4a88-a656-09469e384e4f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "    <p>🚨 &nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Also, the answer depends on the web search results since the question asks for current market cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c6e98",
   "metadata": {
    "height": 334
   },
   "outputs": [],
   "source": [
    "def web_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    agent_query = state.get(\"agent_query\")\n",
    "    result = web_search_agent.invoke({\"messages\":agent_query})\n",
    "    goto = \"executor\"\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"web_researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of research agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "## 2.5 Create charting agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bae808",
   "metadata": {},
   "source": [
    "If the user asks for the results to be charted, then the charting sub-agent can help with that. It first generates the Python code that generates the chart, and then executes the code using the `python_repl_tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17422908-7831-486f-acdc-5e5c44c7326f",
   "metadata": {
    "height": 402
   },
   "outputs": [],
   "source": [
    "from helper import python_repl_tool\n",
    "\n",
    "# Chart generator agent and node\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, \n",
    "# WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "chart_agent = create_react_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    prompt=agent_system_prompt(\n",
    "        \"\"\"\n",
    "        You can only generate charts. You are working with a researcher \n",
    "        colleague.\n",
    "        1) Print the chart first.\n",
    "        2) Save the chart to a file in the current working directory.\n",
    "        3) At the very end of your message, output EXACTLY two lines \n",
    "        so the summarizer can find them:\n",
    "           CHART_PATH: <relative_path_to_chart_file>\n",
    "           CHART_NOTES: <one concise sentence summarizing the main insight in the chart>\n",
    "        Do not include any other trailing text after these two lines.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34f2d",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "def chart_node(state: State) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "    result = chart_agent.invoke(state)\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "    )\n",
    "    goto=\"chart_summarizer\"\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832ebba-d72f-4e69-bf98-3f3af46e2810",
   "metadata": {},
   "source": [
    "## 2.6 Create chart summary agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb45506",
   "metadata": {},
   "source": [
    "This sub-agent generates a caption describing the chart generated by the chart generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314eec9-5f96-483e-aba4-940d855f1fdd",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "chart_summary_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[],  # Add image processing tools if available/needed.\n",
    "    prompt=agent_system_prompt(\n",
    "        \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "        + \"Your task is to generate a standalone, concise summary for the provided chart image saved at a local PATH, where the PATH should be and only be provided by your chart generator colleague. The summary should be no more than 3 sentences and should not mention the chart itself.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cab43e",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "def chart_summary_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[END]]:\n",
    "    result = chart_summary_agent.invoke(state)\n",
    "    print(f\"Chart summarizer answer: {result['messages'][-1].content}\")\n",
    "    # Send to the end node\n",
    "    goto = END\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "            \"final_answer\": result[\"messages\"][-1].content,\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dee1d3",
   "metadata": {},
   "source": [
    "## 2.7 Create a Synthesizer (Text Summarizer) Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4a1ec",
   "metadata": {},
   "source": [
    "In the case where the user does not ask for the results to be charted, the synthesizer sub-agent generates text that summarizes the retrieved results (in this case, the web search results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b21d3-f2ae-4b1b-9cf3-256ea03d0c39",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6e703",
   "metadata": {
    "height": 980
   },
   "outputs": [],
   "source": [
    "def synthesizer_node(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"\n",
    "    Creates a concise, human‑readable summary of the entire interaction,\n",
    "    **purely in prose**.\n",
    "\n",
    "    It ignores structured tables or chart IDs and instead rewrites the\n",
    "    relevant agent messages (research results, chart commentary, etc.)\n",
    "    into a short final answer.\n",
    "    \"\"\"\n",
    "    # Gather informative messages for final synthesis\n",
    "    relevant_msgs = [\n",
    "        m.content for m in state.get(\"messages\", [])\n",
    "        if getattr(m, \"name\", None) in (\"web_researcher\", \n",
    "                                        \"chart_generator\", \n",
    "                                        \"chart_summarizer\")\n",
    "    ]\n",
    "\n",
    "    user_question = state.get(\"user_query\", state.get(\"messages\", [{}])[0].content if state.get(\"messages\") else \"\")\n",
    "\n",
    "    synthesis_instructions = (\n",
    "        \"\"\"\n",
    "        You are the Synthesizer. Use the context below to directly \n",
    "        answer the user's question. Perform any lightweight calculations, \n",
    "        comparisons, or inferences required. Do not invent facts not \n",
    "        supported by the context. If data is missing, say what's missing\n",
    "        and, if helpful, offer a clearly labeled best-effort estimate \n",
    "        with assumptions.\\n\\n\n",
    "        Produce a concise response that fully answers the question, with \n",
    "        the following guidance:\\n\n",
    "        - Start with the direct answer (one short paragraph or a tight bullet list).\\n\n",
    "        - Include key figures from any 'Results:' tables (e.g., totals, top items).\\n\n",
    "        - If any message contains citations, include them as a brief 'Citations: [...]' line.\\n\n",
    "        - Keep the output crisp; avoid meta commentary or tool instructions.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    summary_prompt = [\n",
    "        HumanMessage(content=(\n",
    "            f\"User question: {user_question}\\n\\n\"\n",
    "            f\"{synthesis_instructions}\\n\\n\"\n",
    "            f\"Context:\\n\\n\" + \"\\n\\n---\\n\\n\".join(relevant_msgs)\n",
    "        ))\n",
    "    ]\n",
    "\n",
    "    llm_reply = llm.invoke(summary_prompt)\n",
    "\n",
    "    answer = llm_reply.content.strip()\n",
    "    print(f\"Synthesizer answer: {answer}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"final_answer\": answer,\n",
    "            \"messages\": [HumanMessage(content=answer, name=\"synthesizer\")],\n",
    "        },\n",
    "        goto=END,           # hand off to the END node\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810f00e",
   "metadata": {},
   "source": [
    "## 2.8 Build the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb15bf4",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"web_researcher\", web_research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783bb21",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3b1fe",
   "metadata": {},
   "source": [
    "## 2.9 Use the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e173629",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ⏳ </b> The following two queries might take <b>2-5 minutes</b> to output the results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b0d76-b8be-4a30-80e4-ee470680dbd0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "<p>🚨 &nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video. For example: \n",
    "\n",
    "In the first query, the agent might decide to call the synthesizer instead of calling the chart generator. In this case, you will only see text summarizing the web search results instead of a chart, which means the agent's answer is not completely relevant to the user's query. This is what you'll learn how to evaluate in the next lessons.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f640f",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "import json\n",
    "\n",
    "query = \"Chart the current market capitalization of the top 5 banks in the US?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"web_researcher\", \"chart_generator\", \n",
    "                               \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03180c6",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "query = \"Identify current regulatory changes for the financial services industry in the US.\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"web_researcher\", \"chart_generator\", \n",
    "                               \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
