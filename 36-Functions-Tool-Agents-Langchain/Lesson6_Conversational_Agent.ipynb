{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98d278819f643b0",
   "metadata": {},
   "source": [
    "# Conversational agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf48e71d9bd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6a5207056468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str).replace(tzinfo=datetime.timezone.utc) for time_str in results['hourly']['time']]\n",
    "\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155611b96ee286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            wikipedia.exceptions.PageError,\n",
    "            wikipedia.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d73d0fbcac28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_temperature, search_wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77bf32a5ddd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be75ad34fbe920",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774e29f702a8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather is sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe50d760fb1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tool\n",
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581eb40b94c906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bac8762aa87a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "result1 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\",\n",
    "    \"agent_scratchpad\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920367c4077f618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0ba6b793fbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e44dbfae995ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation=get_current_temperature(result1.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6df878e24cbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1142496f1573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed119f2f2a8d5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.message_log\n",
    "format_to_openai_functions([(result1,observation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787685377423da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = chain.invoke({\n",
    "    \"input\":\"what is the weather in sf\",\n",
    "    \"agent_scratchpad\": format_to_openai_functions([(result1,observation)])\n",
    "})\n",
    "\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f6c4620999b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85513c2a608c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af3c9490fd10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = agent_chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"intermediate_steps\": intermediate_steps\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb41b076b356be",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent(\"what is the weather is sf?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81481bcc19cec44b",
   "metadata": {},
   "source": [
    "# Create a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248208632bdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_your_own(query: str) -> str:\n",
    "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
    "    print(type(query))\n",
    "    return query[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292964978c3d8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_temperature, search_wikipedia, create_your_own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e3ad252a1a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor\n",
    "import panel as pn  \n",
    "pn.extension()\n",
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are helpful but sassy assistant\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
    "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "    \n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde6c78-32f7-4d2f-a38a-89a83524302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbfs(tools)\n",
    "\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=400),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0cdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lab 36)",
   "language": "python",
   "name": "36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
