{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "#memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7aa658-e07b-4451-9405-354ba8c94d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# def from_conn_stringx(cls, conn_string: str,) -> \"SqliteSaver\":\n",
    "#     return SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "# SqliteSaver.from_conn_stringx=classmethod(from_conn_stringx)\n",
    "# memory = SqliteSaver.from_conn_stringx(\":memory:\")\n",
    "# type(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23b865-c2bf-424c-a688-4ae5bf982184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to allow sqlite to allow requests from other python threads (read only - not write safe)\n",
    "# import sqlite3\n",
    "# conn_string = \":memory:\"\n",
    "# memory = SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def inc_steps(left: int, right: int) -> int:\n",
    "#    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    lnode: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    queries: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    steps: Annotated[int, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an 3-paragraph essay. \\\n",
    "Write such an outline for the user provided topic. Give the main headers of an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.Just provide the five headings, dont elaborate, this is a short essay.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 3-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26708454-ef04-4fac-9f0e-024c8b7b002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an 3-paragraph essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content,\n",
    "           \"lnode\": \"plan\",\n",
    "            \"steps\": 1,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []  # add to content\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content,\n",
    "            \"queries\": queries.queries,\n",
    "           \"lnode\": \"research_plan\",\n",
    "            \"steps\": 1,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
    "        \"lnode\": \"generate\",\n",
    "        \"steps\": 1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content,\n",
    "           \"lnode\": \"reflect\",\n",
    "            \"steps\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content,\n",
    "           \"lnode\": \"research_critique\",\n",
    "            \"steps\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# conn_string = \":memory:\"\n",
    "# memory = SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "# graph = builder.compile(checkpointer=memory)\n",
    "#graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398985fb-9c27-44c3-906c-b2b941936c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disp_state():\n",
    "    current_state = graph.get_state(thread)\n",
    "    lnode = current_state.values[\"lnode\"]\n",
    "    asteps = current_state.values[\"steps\"]\n",
    "    rev = current_state.values[\"revision_number\"]\n",
    "    nnode = current_state.next\n",
    "    #step = steps[thread_id]\n",
    "    print  (lnode,nnode,thread_id,rev,asteps)\n",
    "    return lnode,nnode,thread_id,rev,asteps\n",
    "\n",
    "\n",
    "partial_message = \"\" #global to hold state \n",
    "response = {}\n",
    "max_steps = 10\n",
    "steps = []\n",
    "threads = []\n",
    "def run_agent(start,topic,stop_after):\n",
    "    global partial_message, thread_id,thread\n",
    "    global response, max_steps, steps, threads\n",
    "    if start:\n",
    "        steps.append(0)\n",
    "        config = {'task': topic,\"max_revisions\": 2,\"revision_number\": 0} \n",
    "        thread_id += 1  # new agent, new thread\n",
    "        threads.append(thread_id)\n",
    "    else:\n",
    "        config = None\n",
    "    thread = {\"configurable\": {\"thread_id\": str(thread_id)}}\n",
    "    while steps[thread_id] < max_steps:\n",
    "        response = graph.invoke(config, thread)\n",
    "        steps[thread_id] += 1\n",
    "        partial_message += str(response)\n",
    "        partial_message += f\"\\n------------------\\n\\n\"\n",
    "        lnode,nnode,_,rev,asteps = get_disp_state()\n",
    "        yield partial_message,lnode,nnode,thread_id,rev,asteps\n",
    "        config = None #need\n",
    "        if not nnode:  \n",
    "            print(\"Hit the end\")\n",
    "            return\n",
    "        if lnode in stop_after:\n",
    "            print(f\"stopping due to stop_after {lnode}\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Not stopping on lnode {lnode}\")\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_keys(['__start__', 'planner', 'generate', 'reflect', 'research_plan', 'research_critique'])\n",
    "import sqlite3\n",
    "conn_string = \":memory:\"\n",
    "memory = SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_after=['planner', 'generate', 'reflect', 'research_plan', 'research_critique']\n",
    ")\n",
    "thread_id = -1\n",
    "thread = {\"configurable\": {\"thread_id\": str(thread_id)}}\n",
    "\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def get_state(key):\n",
    "    current_values = graph.get_state(thread)\n",
    "    if key in current_values.values:\n",
    "        lnode,nnode,thread_id,rev,astep = get_disp_state()\n",
    "        new_label = f\"last_node: {lnode}, thread_id: {thread_id}, rev: {rev}, step: {astep}\"\n",
    "        return gr.update(label=new_label, value=current_values.values[key])\n",
    "    else:\n",
    "        return \"\"  \n",
    "\n",
    "def get_content():\n",
    "    current_values = graph.get_state(thread)\n",
    "    if \"content\" in current_values.values:\n",
    "        content = current_values.values[\"content\"]\n",
    "        lnode,nnode,thread_id,rev,astep = get_disp_state()\n",
    "        new_label = f\"last_node: {lnode}, thread_id: {thread_id}, rev: {rev}, step: {astep}\"\n",
    "        return gr.update(label=new_label, value=\"\\n\\n\".join(item for item in content) + \"\\n\\n\")\n",
    "    else:\n",
    "        return \"\"  \n",
    "\n",
    "def update_pd():\n",
    "    return gr.Dropdown(label=\"choose thread\", choices=threads, value=thread_id,interactive=True)\n",
    "\n",
    "def switch_state(new_tid):\n",
    "    global thread, thread_id\n",
    "    #print(f\"switch_state{new_tid}\")\n",
    "    thread = {\"configurable\": {\"thread_id\": str(new_tid)}}\n",
    "    thread_id = new_tid\n",
    "    return get_disp_state()\n",
    "\n",
    "def modify_state(key,asnode,new_state):\n",
    "    print(f\"modify_state: {key}\\n{new_state}\")\n",
    "    current_values = graph.get_state(thread)\n",
    "    print(f\"modify_state before: {key}\\n{current_values.values[key]}\")\n",
    "    current_values.values[key] = new_state\n",
    "    graph.update_state(thread, current_values.values,as_node=asnode)\n",
    "    print(f\"modify_state: {key}\\n{current_values.values[key]}\")\n",
    "    return\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Default(spacing_size='sm',text_size=\"sm\")) as demo:\n",
    "    with gr.Tab(\"Agent\"):\n",
    "        with gr.Row():\n",
    "            topic = gr.Textbox(label=\"Essay Topic\", value=\"Pizza Shop\")\n",
    "            write_btn = gr.Button(\"Generate Essay\", scale=0,min_width=80)\n",
    "            cont_btn = gr.Button(\"Continue Essay\", scale=0,min_width=80)\n",
    "        checks = [\"plan\", \"research_plan\", \"generate\", \"reflect\", \"research_critique\"]\n",
    "        stop_after = gr.CheckboxGroup(checks,label=\"Stop After State\", value=checks)\n",
    "        with gr.Row():\n",
    "            lnode = gr.Textbox(label=\"last node\", min_width=100)\n",
    "            nnode = gr.Textbox(label=\"next node\", min_width=100)\n",
    "            threadid = gr.Textbox(label=\"Thread\", scale=0, min_width=80)\n",
    "            revision = gr.Textbox(label=\"Draft Rev\", scale=0, min_width=80)\n",
    "            stepsbox = gr.Textbox(label=\"steps\", scale=0, min_width=80)\n",
    "        with gr.Accordion(\"Edit State\", open=False):\n",
    "            with gr.Row():\n",
    "                thread_pd = gr.Dropdown(choices=threads,interactive=True, label=\"select thread\")\n",
    "                thread_pd.change(switch_state, [thread_pd], [lnode,nnode,threadid,revision,stepsbox])\n",
    "        live = gr.Textbox(label=\"Live Agent Output\", lines=5)\n",
    "        write_btn.click(fn=run_agent, inputs=[gr.Number(True, visible=False),topic,stop_after], \n",
    "                        outputs=[live,lnode,nnode,threadid,revision,stepsbox]).then(\n",
    "                        fn=update_pd, inputs=None, outputs=[thread_pd]) #rewriting thread_pulldown also kicks off update to same outputs..\n",
    "        cont_btn.click(fn=run_agent, inputs=[gr.Number(False, visible=False),topic,stop_after], \n",
    "                       outputs=[live,lnode,nnode,threadid,revision,stepsbox])\n",
    "    with gr.Tab(\"Plan\"):\n",
    "        with gr.Row():\n",
    "            refresh_btn = gr.Button(\"Refresh\")\n",
    "            modify_btn = gr.Button(\"Modify\")\n",
    "        plan = gr.Textbox(label=\"Plan\", lines=10, interactive=True)\n",
    "        refresh_btn.click(fn=get_state, inputs=gr.Number(\"plan\", visible=False), outputs=plan)\n",
    "        modify_btn.click(fn=modify_state, inputs=[gr.Number(\"plan\", visible=False),\n",
    "                                                  gr.Number(\"planner\", visible=False), \n",
    "                                                  plan], outputs=None)\n",
    "    with gr.Tab(\"Research Content\"):\n",
    "        refresh_btn = gr.Button(\"Refresh\")\n",
    "        content = gr.Textbox(label=\"content\", lines=10)\n",
    "        refresh_btn.click(fn=get_content, inputs=None, outputs=content)\n",
    "    with gr.Tab(\"Draft\"):\n",
    "        with gr.Row():\n",
    "            refresh_btn = gr.Button(\"Refresh\")\n",
    "            modify_btn = gr.Button(\"Modify\")\n",
    "        draft = gr.Textbox(label=\"draft\", lines=10, interactive=True)\n",
    "        refresh_btn.click(fn=get_state, inputs=gr.Number(\"draft\", visible=False), outputs=draft)\n",
    "        modify_btn.click(fn=modify_state, inputs=[gr.Number(\"draft\", visible=False),\n",
    "                                                  gr.Number(\"generate\", visible=False), \n",
    "                                                  draft], outputs=None)\n",
    "    with gr.Tab(\"Critique\"):\n",
    "        with gr.Row():\n",
    "            refresh_btn = gr.Button(\"Refresh\")\n",
    "            modify_btn = gr.Button(\"Modify\")\n",
    "        critique = gr.Textbox(label=\"Critique\", lines=10, interactive=True)\n",
    "        refresh_btn.click(fn=get_state, inputs=gr.Number(\"critique\", visible=False), outputs=critique)\n",
    "        modify_btn.click(fn=modify_state, inputs=[gr.Number(\"critique\", visible=False),\n",
    "                                                  gr.Number(\"reflect\", visible=False), \n",
    "                                                  critique], outputs=None)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ba0b0-045c-4454-b579-6fb8bd233319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12345678901234567890123456789012345678901234567890123456789012345678912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a672665-6282-48dd-af84-e4621777a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ebb43-b582-490c-9c72-f3c8c75e4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff44554-16ad-45c2-9375-4454e6506307",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c69433-fae5-4cfc-9683-4cee70d534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values = graph.get_state(thread)\n",
    "current_values.values['plan']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6805ea-6d06-4829-866f-d5bbd4e35f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "astring = \"\"\n",
    "for item in alist:\n",
    "    astring += item + \"\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb57ce-2810-4f60-b2e6-9440086522ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(astring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_values.values[\"plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys(['task', 'plan', 'draft', 'critique', 'content', 'revision_number', 'max_revisions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = list(graph.get_state_history(thread))\n",
    "hist[0].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.get_state_history(thread))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048f2c-4d82-49a5-9cb1-918d78b39f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_after[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7f1f-68b4-4462-bfa5-b6472ef1304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac0aa9-baa7-4b58-889d-2118cc00c6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6098b9-e2a9-4767-8cb5-346db835c8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23cf2a-a179-44dc-9ae3-2eddda4b67b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6005b-0221-4f5e-9be0-0580c1d03126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ec12-f1c8-41ae-bb3e-5f28997b9b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c07d7-be17-4c17-82c5-6fe1db028b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04592c8e-1cfe-4b26-93b5-caf1ed1e7d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c4a9-0e71-4f67-b71f-18a225e37202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c478a9-7bfe-49e2-8a7d-1536271f45a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6771-3fad-4f37-9b32-45b36ad85c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629eb3-655d-467a-b413-63f547c2de08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772f251-2b61-4d10-97c5-61cef9207a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92979-7ac5-4a7c-91c1-10806b7d529c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4325-f625-4bbf-9d74-cc58f10763f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4070be7-72da-42f9-a25d-8a6c628788b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289efbe-7033-4f32-8482-2039c5f9db90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e480bb-22ab-4acb-a42c-71da3d04a5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea35c-7483-4b3d-b5e3-76eb3a0fe536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5730-a9d5-4ea4-8546-ebcb265cf1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f28b-46d8-4bcd-b2e4-730376ee7ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7020-b4f4-4bd2-a875-ccee93f83d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f79eb9-d1c9-44b0-9efd-a8f9b380332a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509206-bde1-43e4-a88f-8a565539d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1590-9e7b-4c0f-9492-81a07d286c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe4a8-5372-479d-b248-af7a295c86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514720a-14bc-4552-ade5-fa03f86f4c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
