{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fa2e13-567d-4509-9023-c99fb230f31f",
   "metadata": {},
   "source": [
    "# Lesson 2 : LangGraph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 79
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool = \u001b[43mTavilySearchResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#increased number of results\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(tool))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(tool.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/ES/OpenAI-labs/83-agentic-langgraph/myenv/lib/python3.12/site-packages/pydantic/v1/main.py:345\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m values, fields_set, validation_error = \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/ES/OpenAI-labs/83-agentic-langgraph/myenv/lib/python3.12/site-packages/pydantic/v1/main.py:1070\u001b[39m, in \u001b[36mvalidate_model\u001b[39m\u001b[34m(model, input_data, cls)\u001b[39m\n\u001b[32m   1067\u001b[39m     errors.append(ErrorWrapper(MissingError(), loc=field.alias))\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m value = \u001b[43mfield\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.validate_all \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field.validate_always:\n\u001b[32m   1073\u001b[39m     values[name] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/ES/OpenAI-labs/83-agentic-langgraph/myenv/lib/python3.12/site-packages/pydantic/v1/fields.py:437\u001b[39m, in \u001b[36mModelField.get_default\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mget_default\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m smart_deepcopy(\u001b[38;5;28mself\u001b[39m.default) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/ES/OpenAI-labs/83-agentic-langgraph/myenv/lib/python3.12/site-packages/pydantic/v1/main.py:347\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    345\u001b[39m values, fields_set, validation_error = validate_model(__pydantic_self__.\u001b[34m__class__\u001b[39m, data)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    349\u001b[39m     object_setattr(__pydantic_self__, \u001b[33m'\u001b[39m\u001b[33m__dict__\u001b[39m\u001b[33m'\u001b[39m, values)\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196c186-af55-4f2d-b569-b7d63a859304",
   "metadata": {},
   "source": [
    "> If you are not familiar with python typing annotation, you can refer to the [python documents](https://docs.python.org/3/library/typing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7ba73-e603-453b-b06f-5db92c567b19",
   "metadata": {},
   "source": [
    "> Note: in `take_action` below, some logic was added to cover the case that the LLM returned a non-existent tool name. Even with function calling, LLMs can still occasionally hallucinate. Note that all that is done is instructing the LLM to try again! An advantage of an agentic organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 742
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6f5f4-2392-41b9-ab96-7919840baa3e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a06a8c-fcd4-4ca6-98f0-36c5809813e6",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  # requires more advanced model\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d643182-2802-40fb-ba35-d4f893c5b976",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
