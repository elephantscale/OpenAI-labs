{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lesson 4: Building a Multi-Document Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b15b97c98324ccbc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "import openai\n",
    "import nest_asyncio\n",
    "\n",
    "openai.api_key = get_openai_api_key()\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4388d555176476c9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup an agent over 3 papers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640ce7e9628f548c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64a2ed625abd514e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
    "    \n",
    "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "len(initial_tools)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deec206ab75544f6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    initial_tools, \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)\n",
    "response = agent.query(\n",
    "    \"Tell me about the evaluation dataset used in LongLoRA, \"\n",
    "    \"and then tell me about the evaluation results\"\n",
    ")\n",
    "response = agent.query(\"Give me a summary of both Self-RAG and LongLoRA\")\n",
    "print(str(response))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bde144626ee16f0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Setup an agent over 11 papers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c8405000a60d3dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
    "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
    "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
    "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
    "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
    "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
    "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"loftq.pdf\",\n",
    "    \"swebench.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "    \"zipformer.pdf\",\n",
    "    \"values.pdf\",\n",
    "    \"finetune_fair_diffusion.pdf\",\n",
    "    \"knowledge_card.pdf\",\n",
    "    \"metra.pdf\",\n",
    "    \"vr_mcl.pdf\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478beb0b333d565f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import get_doc_tools\n",
    "from pathlib import Path\n",
    "\n",
    "paper_to_tools_dict = {}\n",
    "for paper in papers:\n",
    "    print(f\"Getting tools for paper: {paper}\")\n",
    "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
    "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
    "    \n",
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cb9487eb2d5ca4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "tools = obj_retriever.retrieve(\n",
    "    \"Tell me about the eval dataset used in MetaGPT and SWE-Bench\"\n",
    ")\n",
    "tools[2].metadata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3d06fda8857279f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)\n",
    "\n",
    "response = agent.query(\n",
    "    \"Tell me about the evaluation dataset used \"\n",
    "    \"in MetaGPT and compare it against SWE-Bench\"\n",
    ")\n",
    "print(str(response))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "349c5979b7bcdecb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
    "    \"Analyze the approach in each paper first. \"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c997876edaa989c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(str(response))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32df927ec047ce03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a09ecef4b2383144"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
