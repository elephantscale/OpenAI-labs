{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lesson 2: Tool Calling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f1092eed005a2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import openai\n",
    "import nest_asyncio\n",
    "\n",
    "openai.api_key = get_openai_api_key()\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4fd2e433fdd18c7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Define a Simple Tool"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18f3232134fd0ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"add two numbers\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool],\n",
    "    \"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6794065a239bcc81",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define an Auto-Retrieval Tool"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffa83d71c768f897"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "document = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(document)\n",
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fe40b373c329beb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4756a1f755f1b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT?\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62e718e5366d2a37",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(str(response))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89fdd361e66c03bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee2c482f4aa75c23",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the Auto-Retrieval Tool"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aaa4711fda7d11a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    page_numbers: List[str]\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [\n",
    "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "    \n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d6e0dd8c431307e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"What are the high-level results of MetaGPT as described on page 2?\", \n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772b0398a618ac32",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30db51eb1495d624",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT\"\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "526a7c49c4e1e2e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\", \n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee7b4bcf4f2ffbff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1748e2975c53b6ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What is a summary of the paper?\", \n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98405ff3a036fca3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1a2d48ea563dc939"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
