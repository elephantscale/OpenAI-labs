{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lesson 5. Model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd2af70ad76544c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "26f1efa8e72f0d2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load the model to be trained"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36fb31e8bdd3fa5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./models/upstage/TinySolar-308m-4k-init\",\n",
    "    device_map=\"cpu\", \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    ")\n",
    "pretrained_model"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4947bb3dd9fe141c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232201839c55e825"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, args, split=\"train\"):\n",
    "        \"\"\"Initializes the custom dataset object.\"\"\"\n",
    "        self.args = args\n",
    "        self.dataset = datasets.load_dataset(\n",
    "            \"parquet\",\n",
    "            data_files=args.dataset_name,\n",
    "            split=split\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single data sample from the dataset \n",
    "        at the specified index\n",
    "        \"\"\"\n",
    "        input_ids = torch.LongTensor(self.dataset[idx][\"input_ids\"])\n",
    "        labels = torch.LongTensor(self.dataset[idx][\"input_ids\"])\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe9a0ee2065e8ab1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Configure Training Arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "975ef3c7d1f411f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import transformers\n",
    "\n",
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    dataset_name: str = field(                           \n",
    "        default=\"./parquet/packaged_pretrain_dataset.parquet\")\n",
    "    num_proc: int = field(default=1)                     \n",
    "    max_seq_length: int = field(default=32)              \n",
    "\n",
    "    seed: int = field(default=0)                         \n",
    "    optim: str = field(default=\"adamw_torch\")            \n",
    "    max_steps: int = field(default=30)                   \n",
    "    per_device_train_batch_size: int = field(default=2)  \n",
    "\n",
    "    learning_rate: float = field(default=5e-5)           \n",
    "    weight_decay: float = field(default=0)               \n",
    "    warmup_steps: int = field(default=10)                \n",
    "    lr_scheduler_type: str = field(default=\"linear\")     \n",
    "    gradient_checkpointing: bool = field(default=True)   \n",
    "    dataloader_num_workers: int = field(default=2)       \n",
    "    bf16: bool = field(default=True)                     \n",
    "    gradient_accumulation_steps: int = field(default=1)  \n",
    "    \n",
    "    logging_steps: int = field(default=3)                \n",
    "    report_to: str = field(default=\"none\") "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7bf6315c2158b41"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parser = transformers.HfArgumentParser(CustomArguments)\n",
    "args, = parser.parse_args_into_dataclasses(\n",
    "    args=[\"--output_dir\", \"output\"]\n",
    ")\n",
    "train_dataset = CustomDataset(args=args)\n",
    "print(\"Input shape: \", train_dataset[0]['input_ids'].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff1d525f71fd06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Run the trainer and monitor the loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d69f0e0a40fd2c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class LossLoggingCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            self.logs.append(logs)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "\n",
    "loss_logging_callback = LossLoggingCallback()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1acde0b7e0ad4dce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking the performance of an intermediate checkpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6821200c6d6e7da3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"./models/upstage/TinySolar-248m-4k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8793ced1d336c28f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import TextStreamer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name_or_path = \"./models/output/checkpoint-10000\"\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,    \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d081af4c62fda0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = \"I am an engineer. I love\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model2.device)\n",
    "\n",
    "streamer = TextStreamer(\n",
    "    tokenizer, \n",
    "    skip_prompt=True, \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "outputs = model2.generate(\n",
    "    **inputs, \n",
    "    streamer=streamer, \n",
    "    use_cache=True, \n",
    "    max_new_tokens=64,     \n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2186805a82c2215e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
