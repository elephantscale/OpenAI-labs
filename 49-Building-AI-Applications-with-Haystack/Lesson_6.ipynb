{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20365459007b97b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# L6: Chat Agent with Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecaa22359f7c69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from helper import load_env\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379bb4198527089",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import gradio as gr\n",
    "from typing import List\n",
    "from haystack import component, Pipeline, Document\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.generators.chat.openai import OpenAIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.joiners import BranchJoiner\n",
    "from haystack_experimental.components.tools import OpenAIFunctionCaller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d33a0f5a3b1ea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create RAG Pipeline as a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73010def32873a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "rag_pipe = Pipeline()\n",
    "rag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipe.add_component(\"llm\", OpenAIGenerator())\n",
    "\n",
    "rag_pipe.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63569382c1652c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def rag_pipeline_func(query: str):\n",
    "    documents = [\n",
    "        Document(content=\"My name is Jean and I live in Paris.\"),\n",
    "        Document(content=\"My name is Mark and I live in Berlin.\"),\n",
    "        Document(content=\"My name is Giorgio and I live in Rome.\"),\n",
    "        Document(content=\"My name is Marta and I live in Madrid.\"),\n",
    "        Document(content=\"My name is Harry and I live in London.\"),\n",
    "    ]\n",
    "    result = rag_pipe.run({\"prompt_builder\": {\"question\": query, \n",
    "                                              \"documents\": documents}})\n",
    "    return {\"reply\": result[\"llm\"][\"replies\"][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce5e6890975450",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create a Weather Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4409dab3bc2513",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "WEATHER_INFO = {\n",
    "    \"Berlin\": {\"weather\": \"mostly sunny\", \"temperature\": 7, \"unit\": \"celsius\"},\n",
    "    \"Paris\": {\"weather\": \"mostly cloudy\", \"temperature\": 8, \"unit\": \"celsius\"},\n",
    "    \"Rome\": {\"weather\": \"sunny\", \"temperature\": 14, \"unit\": \"celsius\"},\n",
    "    \"Madrid\": {\"weather\": \"sunny\", \"temperature\": 10, \"unit\": \"celsius\"},\n",
    "    \"London\": {\"weather\": \"cloudy\", \"temperature\": 9, \"unit\": \"celsius\"},\n",
    "}\n",
    "\n",
    "def get_current_weather(location: str):\n",
    "    if location in WEATHER_INFO:\n",
    "        return WEATHER_INFO[location]\n",
    "    else:\n",
    "        return {\"weather\": \"sunny\", \"temperature\": 70, \"unit\": \"fahrenheit\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad41f8fefeb77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aea7d0c7f51d77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_pipeline_func\",\n",
    "            \"description\": \"Get information about where people live\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"The city\"}\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff604b4fe66dc09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create an OpenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa0782c3b479ee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chat_generator = OpenAIChatGenerator(model=\"gpt-3.5-turbo\", generation_kwargs={'tools': tools})\n",
    "replies = chat_generator.run(messages=[ChatMessage.from_user(\"Where does Mark live?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6a764457c0e7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(replies['replies'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd08f843f62c00a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb05318fbf9ede",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "function_caller = OpenAIFunctionCaller(available_functions={\"rag_pipeline_func\": rag_pipeline_func, \n",
    "                                                            \"get_current_weather\": get_current_weather})\n",
    "\n",
    "results = function_caller.run(messages=replies['replies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda08e582bbbbbb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(results[\"function_replies\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5163abba2c4e85",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create a Chat Agent with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec83c14a2ad9f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "message_collector = BranchJoiner(List[ChatMessage])\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-3.5-turbo\", generation_kwargs={'tools': tools})\n",
    "function_caller = OpenAIFunctionCaller(available_functions={\"rag_pipeline_func\": rag_pipeline_func, \n",
    "                                                            \"get_current_weather\": get_current_weather})\n",
    "\n",
    "chat_agent = Pipeline()\n",
    "chat_agent.add_component(\"message_collector\", message_collector)\n",
    "chat_agent.add_component(\"generator\", chat_generator)\n",
    "chat_agent.add_component(\"function_caller\", function_caller)\n",
    "\n",
    "chat_agent.connect(\"message_collector\", \"generator.messages\")\n",
    "chat_agent.connect(\"generator\", \"function_caller\")\n",
    "chat_agent.connect(\"function_caller.function_replies\", \"message_collector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590d24f4c3e0be4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "chat_agent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23a9b47a9396e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"\"\"If needed, break down the user's question into simpler questions and follow-up questions that you can use with your tools.\n",
    "        Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\"\"\n",
    "    )\n",
    "]\n",
    "while True:\n",
    "    user_input = input(\"INFO: Type 'exit' or 'quit' to stop\\n\")\n",
    "    if user_input.lower() == \"exit\" or user_input.lower() == \"quit\":\n",
    "        break\n",
    "    messages.append(ChatMessage.from_user(user_input))\n",
    "    response = chat_agent.run({\"message_collector\": {\"value\": messages}})\n",
    "    messages.extend(response['function_caller']['assistant_replies'])\n",
    "    print(response['function_caller']['assistant_replies'][0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ca9e52944b097",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Gradio Chat App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c19982b0ed75e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "        ChatMessage.from_system(\n",
    "            \"\"\"If needed, break down the user's question to simpler questions and follow-up questions that you can use with your tools.\n",
    "            Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\"\"\n",
    "        )\n",
    "    ]\n",
    "def chat(message, history): \n",
    "    messages.append(ChatMessage.from_user(message))\n",
    "    response = chat_agent.run({\"message_collector\": {\"value\": messages}})\n",
    "    messages.extend(response['function_caller']['assistant_replies'])\n",
    "    return response['function_caller']['assistant_replies'][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05d4537becc254",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    examples=[\n",
    "        \"Can you tell me where Giorgio lives?\",\n",
    "        \"What's the weather like in Madrid?\",\n",
    "        \"Who lives in London?\",\n",
    "        \"What's the weather like where Mark lives?\",\n",
    "    ],\n",
    "    title=\"Ask me about weather or where people live!\",\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
