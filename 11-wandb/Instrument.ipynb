{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb6180c-7028-4907-b1db-eaf7d67132e7",
   "metadata": {},
   "source": [
    "# Introduction to W&B\n",
    "\n",
    "<!--- @wandbcode{dlai_01} -->\n",
    "\n",
    "We will add `wandb` to sprite classification model training, so that we can track and visualize important metrics, gain insights into our model's behavior and make informed decisions for model improvements. We will also see how to compare and analyze different experiments, collaborate with team members, and reproduce results effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac533ff5-200f-4637-b74d-89944403097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'utilities' package is not available.\n",
      "3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:24:37) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import utilities\n",
    "    print(\"The 'utilities' package is available.\")\n",
    "except ImportError:\n",
    "    print(\"The 'utilities' package is not available.\")\n",
    "import sys\n",
    "print(sys.version)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bdc02-7a6f-40f4-b611-7f8bfb68e9c4",
   "metadata": {},
   "source": [
    "### Sprite classification\n",
    "\n",
    "We will build a simple model to classify sprites. You can see some examples of sprites and corresponding classes in the image below.\n",
    "\n",
    "<img src=\"sprite_sample.webp\" alt=\"Alt Text\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f8bf2-aed3-4b22-8d25-5abd67e13df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * 16 * 16\n",
    "OUTPUT_SIZE = 5\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "CLASSES = [\"hero\", \"non-hero\", \"food\", \"spell\", \"side-facing\"]\n",
    "DATA_DIR = Path('./data/')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "def get_model(dropout):\n",
    "    \"Simple MLP with Dropout\"\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
    "        nn.BatchNorm1d(HIDDEN_SIZE),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dea51-8513-4322-8b14-5c893f9893ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a config object to store our hyperparameters\n",
    "config = SimpleNamespace(\n",
    "    epochs = 2,\n",
    "    batch_size = 128,\n",
    "    lr = 1e-5,\n",
    "    dropout = 0.5,\n",
    "    slice_size = 10_000,\n",
    "    valid_pct = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71504fbe-8ac0-401a-9f4e-7f7c2be890d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"Train a model with a given config\"\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"dlai_intro\",\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Get the data\n",
    "    train_dl, valid_dl = get_dataloaders(DATA_DIR, \n",
    "                                         config.batch_size, \n",
    "                                         config.slice_size, \n",
    "                                         config.valid_pct)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "    # A simple MLP model\n",
    "    model = get_model(config.dropout)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    example_ct = 0\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs), total=config.epochs):\n",
    "        model.train()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(images)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/epoch\": epoch + 1,\n",
    "                \"train/example_ct\": example_ct\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "        # Compute validation metrics, log images on last epoch\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func)\n",
    "        # Compute train and validation metrics\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/val_accuracy\": accuracy\n",
    "        }\n",
    "        wandb.log(val_metrics)\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb2876-284a-4370-8adf-a9299e6b4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_dl, loss_func):\n",
    "    \"Compute the performance of the model on the validation dataset\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels) * labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44c791-062f-4884-aa44-597ef33eaef1",
   "metadata": {},
   "source": [
    "### W&B account\n",
    "[Sign up](https://wandb.ai/site) for a free account at https://wandb.ai/site and then login to your wandb account to store the results of your experiments and use advanced W&B features. You can also continue to learn in anonymous mode. If you have an existing W&B account, and your browser automatically logs you in, be sure to use it here to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd7a31-5c84-4b7e-81f9-8f1690d29ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1977e-64f9-4633-a6e6-2bcff4a64364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So let's change the learning rate to a 1e-3 \n",
    "# and see how this affects our results.\n",
    "config.lr = 1e-4\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0604e8f5-bc11-494a-b40c-69cddd5c73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.lr = 1e-4\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a4dbe-3a77-4d46-b26f-7a19b70304bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dropout = 0.1\n",
    "config.epochs = 1\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234f970-85b5-4c26-b1a0-150310a5b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.lr = 1e-3\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead5ba6-fdd3-403c-94dd-284579569b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
