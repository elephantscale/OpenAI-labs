{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30694aa9-029f-4010-bed4-0a5c30b66106",
   "metadata": {},
   "source": [
    "# L7: Conversational RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ac10f-477d-40d3-97a3-e8cea3078814",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ce155-7153-4cc6-82e2-9f4026201259",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5fcd3-b07e-46cf-ab7f-4ce8cdbbf85b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977646b-f467-4e95-8fbe-31885271c273",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "import uuid\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c05a58-6346-4746-8a28-f6a74b7f9e7a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8eeeaf-18a8-424d-a312-53a3381edfe0",
   "metadata": {},
   "source": [
    "## Load API key and create AI21Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22225d-18ee-4114-926f-270c380221a3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_ai21_api_key\n",
    "ai21_api_key = get_ai21_api_key()\n",
    "client = AI21Client(api_key=ai21_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613170d-fe40-416c-982c-2ba11bff8e97",
   "metadata": {
    "height": 266
   },
   "outputs": [],
   "source": [
    "from utils import call_convrag\n",
    "\n",
    "conversation_history = []\n",
    "def convrag_response(message):\n",
    "  conversation_history.append(ChatMessage(content=message, role=\"user\"))\n",
    "  chat_response = call_convrag(client, conversation_history)\n",
    "  # the LLM response to user query\n",
    "  response = chat_response.choices[0].content\n",
    "  # most relevant retrieved text segment\n",
    "  text_retrieval = chat_response.sources[0].text\n",
    "  # the file contains the retrieved text segment\n",
    "  file_retrieval = chat_response.sources[0].file_name\n",
    "  conversation_history.append(ChatMessage(content=response, role=\"assistant\"))\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb78cce-079d-4f18-a2b7-03522e2d0637",
   "metadata": {},
   "source": [
    "## Prompt the Conversational RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b589ed4-1620-48b3-a3f3-bc13747a512c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8b996-f740-447e-b1f3-2578280f4854",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "message = \"You are a financial analyst and what is the summary with Nvidia annual earnings report?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84596ad-d502-4a55-846a-8b8ac120ee56",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "message = \"How much did the Nvidia's revenue increase in the period?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c68d5b6-b7c4-4fa5-bb7b-2e4393e7d1e8",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "message = \"Should I buy Nvidia stock now?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ff720-0206-450d-9f25-04ac93163f74",
   "metadata": {},
   "source": [
    "## Create a gradio chat app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8948e68-ca41-4497-9de0-e482c8c0b03f",
   "metadata": {
    "height": 368
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=convrag_response,\n",
    "    inputs=[gr.Textbox(label=\"Your questions:\", lines=2)],\n",
    "    outputs=[gr.Textbox(label=\"AI21 Conversational RAG answer:\", lines=2)],\n",
    "    examples=[\n",
    "    \"How have revenue, gross margin, and net income trended over the past year?\",\n",
    "    \"What are the actions taken by the company about sustainability?\",\n",
    "    \"What are the main risks of the company?\",\n",
    "    \"How is the company allocating its capital (e.g., dividends, share repurchases, acquisitions)?\",\n",
    "    \"Are there any concerning trends in operating cash flow?\",\n",
    "    ],\n",
    "    title=\"Nvidia 10-K Q&A\",\n",
    "    description=\"Use AI21 Conversational RAG to retrieval insights from SEC filings\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf3879-1cde-4bdc-9892-5e7c69d48da8",
   "metadata": {},
   "source": [
    "## RAG with AI21 Jamba model in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3136b5f-4cf8-4a42-9acd-858ff34d5915",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "from langchain_ai21 import ChatAI21\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7d2c5-681c-49db-a697-8bd186855455",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "llm = ChatAI21(model=\"jamba-1.5-large\",\n",
    "               max_tokens = 4096,\n",
    "               temperature = 0.4,\n",
    "               top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0786ad5-f719-4d6c-ad93-022994d8b6ef",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./Nvidia_10K_20240128.txt\")\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d79a7-171b-4b96-adc5-6723f1da1f9c",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400)\n",
    "documents = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda248e-94fb-4c8c-a26b-59afbd9fa1a0",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd682da4-1661-46c6-a619-232f0fdcd8a4",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677c26b-36ef-42e7-bc97-b4bec692d597",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in answering questions based on provided context.\n",
    "    Answer the question based on the provided context below to the best of your ability.\n",
    "    The response must be complete, coherent and concise.\n",
    "    If the answer is not contained in the context, please respond with \"answer not in the document\"\\n\n",
    "    Here is the context you should use to answer the question: \\n\n",
    "    <context>\n",
    "    {context}\n",
    "    </context> \\n\n",
    "    Based on the provided context, answer the following question: {question} \\n\n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b4925-74f9-402a-9d4a-d242a681e4ae",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e524f-afba-4dd1-9f6d-f7cef551db7a",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a3976-ecc5-44e5-92bb-dbcd1df324e7",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70fb23-a348-4b93-aa99-fcae2e9b4ae9",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "q = \"How has the company revenue and profit changed from last year?\"\n",
    "\n",
    "response = rag_chain.invoke(q)\n",
    "print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9657427-71d6-4a34-9397-c8bc543470a9",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "docs = retriever.invoke(q)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c3a72-0e59-4161-b875-b5db07192b84",
   "metadata": {
    "height": 215
   },
   "outputs": [],
   "source": [
    "questions = [\"What are the main business risks for the company?\",\n",
    "             \"What are the key financial metrics of the company?\",\n",
    "             \"What is the profit growth of the company in the reporting period?\",\n",
    "             \"Did the company have a cybersecurity incident based on the following SEC filing document?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response = rag_chain.invoke(q)\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Question: {q}\")\n",
    "    print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7006f-b0d7-40a0-bff0-b22435db2bd7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b73e4d-555c-47a6-a10f-76fcd73dadb7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f7257-4478-477e-9cd0-7373ccb6be04",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0d69b-f852-44e0-9201-48463a0814b0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76821a5-0fde-4d66-bded-98f0b9e05527",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6f265-f706-4c4f-ac9b-c976dcd292b3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6c853-551a-4aa1-91ed-f2faf4953a47",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
